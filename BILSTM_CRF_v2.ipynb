{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from future.utils import iteritems\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Model, Input\n",
    "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional\n",
    "from keras.optimizers import Adam\n",
    "from keras_contrib.layers import CRF\n",
    "from keras.initializers import he_normal\n",
    "import keras\n",
    "from seqeval.metrics import precision_score, recall_score, f1_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence_dict():\n",
    "    sentence_dict = {}\n",
    "    with open('sentence_dict.json', 'r') as fp:\n",
    "        sentence_dict = json.load(fp)\n",
    "    return sentence_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input_dict(lemma=False):\n",
    "    sentence_dict = get_sentence_dict()\n",
    "    input_dict = {}\n",
    "    if lemma:\n",
    "        idx = 2\n",
    "    else:\n",
    "        idx = 0\n",
    "    for key, sentence in sentence_dict.items():\n",
    "        new_sentence = []\n",
    "        for word in sentence:\n",
    "            new_sentence.append((word[idx], word[1], word[3]))\n",
    "        input_dict[int(float(key))] = new_sentence\n",
    "    return input_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_predictions(y_pred):\n",
    "    conv_pred = []\n",
    "    for pred in y_pred:\n",
    "        conv_tmp = []\n",
    "        for val in pred:\n",
    "            val_arg_max = np.argmax(val)\n",
    "            conv_tmp.append(indices_to_tag[val_arg_max])\n",
    "        conv_pred.append(conv_tmp)\n",
    "    return conv_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"ner_first_preprocessing.csv\")\n",
    "df = df[['sentence_idx', 'word', 'lemma','pos', 'tag']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the appropriate lists and dictionaries that will be used to create the input and output training/test sets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dict = get_input_dict()\n",
    "# List with possible tags\n",
    "tags = ['B-geo', 'B-tim', 'I-gpe', 'I-art', 'B-per', 'I-eve', 'B-gpe', 'I-geo', 'B-eve', 'I-nat', 'B-nat', 'I-org', 'I-tim', 'I-per', 'B-org', 'B-art', 'O']\n",
    "tags_without_O = tags[:-1]\n",
    "# List with unique words in the dataset\n",
    "words = list(set(df[\"word\"].values))\n",
    "words.append(\"EOL\")\n",
    "# Number of unique words \n",
    "number_of_words = len(words)\n",
    "# Number of tags\n",
    "number_of_tags = len(tags)\n",
    "\n",
    "# The words and tags are converted to appropriate numerical representation.\n",
    "word_indices = {w: idx for idx, w in enumerate(words)}\n",
    "tag_indices = {t: idx for idx, t in enumerate(tags)}\n",
    "indices_to_tag = {v: k for k, v in iteritems(tag_indices)}\n",
    "\n",
    "# The input dictionary that containes the preprocessed dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81\n"
     ]
    }
   ],
   "source": [
    "# Length of the longest sentence in the dataset\n",
    "len_max = max([len(s) for s in input_dict.values()])\n",
    "print(len_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the input/output sequences. Use padding, because all of the sentences need to have the same length (Bi-LSTM requirement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_final = [[word_indices[word[0]] for word in s] for s in list(input_dict.values())]\n",
    "output_final = [[tag_indices[t[2]] for t in s] for s in list(input_dict.values())]\n",
    "\n",
    "input_pad = word_indices[\"EOL\"]\n",
    "input_final = pad_sequences(maxlen=len_max, sequences=input_final, padding=\"post\", value=input_pad)\n",
    "output_final = pad_sequences(maxlen=len_max, sequences=output_final, padding=\"post\", value=tag_indices[\"O\"])\n",
    "output_final = [to_categorical(tag, num_classes=len(tags)) for tag in output_final]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(input_final, output_final, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\keras_contrib\\layers\\crf.py:346: UserWarning: CRF.loss_function is deprecated and it might be removed in the future. Please use losses.crf_loss instead.\n",
      "  warnings.warn('CRF.loss_function is deprecated '\n",
      "c:\\program files\\python36\\lib\\site-packages\\keras_contrib\\layers\\crf.py:353: UserWarning: CRF.accuracy is deprecated and it might be removed in the future. Please use metrics.crf_accuracy\n",
      "  warnings.warn('CRF.accuracy is deprecated and it '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_12\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_28 (InputLayer)        (None, 81)                0         \n",
      "_________________________________________________________________\n",
      "embedding_28 (Embedding)     (None, 81, 20)            603460    \n",
      "_________________________________________________________________\n",
      "bidirectional_26 (Bidirectio (None, 81, 80)            19520     \n",
      "_________________________________________________________________\n",
      "time_distributed_24 (TimeDis (None, 81, 17)            1377      \n",
      "_________________________________________________________________\n",
      "crf_22 (CRF)                 (None, 81, 17)            629       \n",
      "=================================================================\n",
      "Total params: 624,986\n",
      "Trainable params: 624,986\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Some of the parameters:\n",
    "embedding_size = 20\n",
    "# lstm_units = embedding_size * 2\n",
    "lstm_units = 40 \n",
    "dropout = 0.5\n",
    "recurrent_dropout = 0.5\n",
    "\n",
    "# Input\n",
    "input_layer = Input(shape=(len_max,))\n",
    "\n",
    "# Embedding Layer\n",
    "model = Embedding(input_dim=number_of_words, output_dim=embedding_size, input_length=len_max)(input_layer)\n",
    "# BI-LSTM Layer\n",
    "model = Bidirectional(LSTM(units=lstm_units, return_sequences=True, \n",
    "                           dropout=dropout, recurrent_dropout=recurrent_dropout, \n",
    "                           kernel_initializer=keras.initializers.he_normal()))(model)\n",
    "# TimeDistributed layer\n",
    "model = TimeDistributed(Dense(number_of_tags, activation=\"relu\"))(model)  \n",
    "# CRF Layer\n",
    "crf = CRF(number_of_tags)\n",
    "\n",
    "# Output \n",
    "output_layer = crf(model) \n",
    "model = Model(input_layer, output_layer)\n",
    "\n",
    "# Optimiser \n",
    "adam = Adam(lr=0.0005, beta_1=0.9, beta_2=0.999)\n",
    "\n",
    "model.compile(optimizer=adam, loss=crf.loss_function, metrics=[crf.accuracy, 'accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25326 samples, validate on 2815 samples\n",
      "Epoch 1/5\n",
      "25326/25326 [==============================] - 93s 4ms/step - loss: 0.3563 - crf_viterbi_accuracy: 0.9217 - accuracy: 0.0097 - val_loss: 0.1354 - val_crf_viterbi_accuracy: 0.9606 - val_accuracy: 0.9606\n",
      "Epoch 2/5\n",
      "25326/25326 [==============================] - 92s 4ms/step - loss: 0.0997 - crf_viterbi_accuracy: 0.9663 - accuracy: 0.0097 - val_loss: 0.0742 - val_crf_viterbi_accuracy: 0.9720 - val_accuracy: 0.9720\n",
      "Epoch 3/5\n",
      "25326/25326 [==============================] - 92s 4ms/step - loss: 0.0580 - crf_viterbi_accuracy: 0.9782 - accuracy: 0.0097 - val_loss: 0.0391 - val_crf_viterbi_accuracy: 0.9850 - val_accuracy: 0.9850\n",
      "Epoch 4/5\n",
      "25326/25326 [==============================] - 100s 4ms/step - loss: 0.0297 - crf_viterbi_accuracy: 0.9862 - accuracy: 0.0097 - val_loss: 0.0229 - val_crf_viterbi_accuracy: 0.9877 - val_accuracy: 0.9877\n",
      "Epoch 5/5\n",
      "25326/25326 [==============================] - 96s 4ms/step - loss: 0.0150 - crf_viterbi_accuracy: 0.9886 - accuracy: 0.0097 - val_loss: 0.0124 - val_crf_viterbi_accuracy: 0.9888 - val_accuracy: 0.9888\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, np.array(y_train), batch_size=32, epochs=5, validation_split=0.1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test, verbose=1)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_labels = convert_predictions(y_pred)\n",
    "real_labels = convert_predictions(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score: 77.54%\n"
     ]
    }
   ],
   "source": [
    "print(\"F1-score: {:.2%}\".format(f1_score(real_labels, pred_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           precision    recall  f1-score   support\n",
      "\n",
      "      gpe       0.94      0.90      0.92      2399\n",
      "      per       0.74      0.66      0.70      2440\n",
      "      geo       0.79      0.85      0.82      5457\n",
      "      org       0.65      0.60      0.63      2966\n",
      "      nat       0.00      0.00      0.00        26\n",
      "      tim       0.85      0.75      0.80      3008\n",
      "      art       0.00      0.00      0.00        72\n",
      "      eve       0.00      0.00      0.00        54\n",
      "\n",
      "micro avg       0.79      0.76      0.78     16422\n",
      "macro avg       0.78      0.76      0.77     16422\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(real_labels, pred_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python36\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-geo       0.81      0.86      0.84      5457\n",
      "       B-tim       0.89      0.79      0.84      3008\n",
      "       I-gpe       0.00      0.00      0.00        27\n",
      "       I-art       0.00      0.00      0.00        49\n",
      "       B-per       0.84      0.75      0.79      2440\n",
      "       I-eve       0.00      0.00      0.00        49\n",
      "       B-gpe       0.95      0.91      0.93      2399\n",
      "       I-geo       0.78      0.62      0.69      1071\n",
      "       B-eve       0.00      0.00      0.00        54\n",
      "       I-nat       0.00      0.00      0.00        11\n",
      "       B-nat       0.00      0.00      0.00        26\n",
      "       I-org       0.74      0.71      0.73      2399\n",
      "       I-tim       0.90      0.45      0.60       903\n",
      "       I-per       0.85      0.80      0.82      2490\n",
      "       B-org       0.71      0.63      0.67      2966\n",
      "       B-art       0.00      0.00      0.00        72\n",
      "\n",
      "   micro avg       0.82      0.76      0.79     23421\n",
      "   macro avg       0.47      0.41      0.43     23421\n",
      "weighted avg       0.82      0.76      0.78     23421\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn_crfsuite.metrics import flat_classification_report  \n",
    "report = flat_classification_report(y_pred=pred_labels, y_true=real_labels, labels = tags_without_O)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seqeval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqeval"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}